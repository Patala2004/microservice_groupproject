volumes:
  models_translation:

networks:
  translation_network:
    driver: bridge



services:
  ollamatranslation:
    image: ollama/ollama
    container_name: ollama-translate
    volumes:
      - models_translation:/root/.ollama
      - ./ollama-init/entrypoint.sh:/entrypoint.sh
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - translation_network
  
  translate:
    build: .
    container_name: translate
    depends_on:
      - ollamatranslation
    ports:
      - "8088:8000"
    environment:
      OLLAMA_HOST: "http://ollama-translate:11434"
    networks:
      - translation_network

